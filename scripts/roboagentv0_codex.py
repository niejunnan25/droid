# é™æ€è§„åˆ’ï¼é™æ€ï¼šä¸€æ¬¡æ€§ç”Ÿæˆæ‰€æœ‰å­ä»»åŠ¡
# ä¿®æ”¹ç‰ˆæœ¬ï¼šæ”¹è¿›çš„æ—¥å¿—ç³»ç»Ÿï¼Œä½¿ç”¨åŒ—äº¬æ—¶é—´ï¼ˆUTC+8ï¼‰ï¼Œç²¾ç¡®åˆ°å¾®ç§’

import dataclasses
import faulthandler
import os
import select
import sys
import threading
import time
from contextlib import contextmanager
from datetime import datetime, timezone, timedelta
from typing import Optional
import concurrent.futures
import json
import re
import concurrent.futures
import json

import numpy as np
import pandas as pd
from PIL import Image
import tyro

from openpi_client import image_tools
from openpi_client import websocket_client_policy
from droid.camera_utils.wrappers import multi_camera_wrapper as mcw
from droid.robot_env import RobotEnv
from ZEDCamera import ZedCamera

from utils import prevent_keyboard_interrupt, clear_input_buffer
from utils import parse_llm_output_to_list_regex, extract_boolean_answer, process_image

from pi05_main import _extract_observation

faulthandler.enable()

# å®šä¹‰åŒ—äº¬æ—¶åŒº (UTC+8)
BEIJING_TZ = timezone(timedelta(hours=8))
CROP_RATIOS = (0.27, 0.13)  # ä¸ pi05_main_async å¯¹é½çš„å·¦å³è£å‰ªæ¯”ä¾‹


def get_beijing_timestamp() -> str:
    """
    è·å–å½“å‰åŒ—äº¬æ—¶é—´çš„æ—¶é—´æˆ³ï¼Œç²¾ç¡®åˆ°å¾®ç§’
    æ ¼å¼: YYYY-MM-DD HH:MM:SS.ffffff
    """
    now = datetime.now(BEIJING_TZ)
    return now.strftime("%Y-%m-%d %H:%M:%S.%f")


def get_beijing_timestamp_short() -> str:
    """
    è·å–å½“å‰åŒ—äº¬æ—¶é—´çš„çŸ­æ—¶é—´æˆ³ï¼Œç²¾ç¡®åˆ°å¾®ç§’
    æ ¼å¼: HH:MM:SS.ffffff
    """
    now = datetime.now(BEIJING_TZ)
    return now.strftime("%H:%M:%S.%f")


@contextmanager
def time_scope(name: str, log_file=None):
    """ç®€å•è®¡æ—¶ä¸Šä¸‹æ–‡ï¼Œå…¼å®¹åŸ timer.timer æ¥å£çš„ç¬¬äºŒä¸ªå‚æ•°ã€‚"""
    start = time.time()
    try:
        yield
    finally:
        duration = time.time() - start
        msg = f"[TIMER] {name}: {duration:.4f}s"
        print(msg)
        if log_file is not None:
            try:
                log_file.write(msg + "\n")
                log_file.flush()
            except Exception:
                pass


@dataclasses.dataclass
class Args:
    left_camera_id: str = "36276705"
    right_camera_id: str = "<your_camera_id>"
    wrist_camera_id: str = "13132609"

    external_camera: Optional[str] = "left"

    fetch_hz: float = 30.0
    first_frame_timeout_s: float = 5.0
    max_timesteps: int = 3600
    max_duration: int = 1800  # seconds

    open_loop_horizon: int = 18
    control_frequency: int = 50

    remote_host: str = "162.105.195.74"
    remote_port: int = 8000

    record_dir: str = "record"

    # TODO: ä¿å­˜éƒ¨ç½²æ•°æ®åŠŸèƒ½å°šæœªå®ç°
    save_deployment_data: bool = False

    max_subtask_timesteps: int = 1200

    use_env_camera: bool = False  # ä»…æ”¯æŒç¦ç”¨ env ç›¸æœºï¼›True å°†æŠ›é”™
    
    vllm_port: Optional[int] = None  # å¦‚æœä¸º Noneï¼Œåˆ™é»˜è®¤ä¸º 8000


class ManualCameraManager:
    """è½»é‡çº§ ZED ç›¸æœºç®¡ç†å™¨ï¼šç¦ç”¨ env ç›¸æœºæ—¶æ‰‹åŠ¨æŠ“å–å¤–éƒ¨ä¸è…•éƒ¨ç›¸æœºã€‚"""

    def __init__(self, args: Args):
        self.args = args
        self.external_serial = self._resolve_external_serial(args)
        self.wrist_serial = args.wrist_camera_id

        self.external_camera = self._init_camera(self.external_serial, "external") if self.external_serial else None
        self.wrist_camera = self._init_camera(self.wrist_serial, "wrist") if self.wrist_serial else None

    def _resolve_external_serial(self, args: Args) -> Optional[str]:
        if args.external_camera == "right":
            return args.right_camera_id
        return args.left_camera_id

    def _init_camera(self, serial: str | None, label: str):
        if not serial or serial == "<your_camera_id>":
            return None
        try:
            return ZedCamera(serial_number=int(serial))
        except Exception as exc:
            raise RuntimeError(f"åˆå§‹åŒ– {label} ZED ç›¸æœºå¤±è´¥ï¼ˆserial={serial}ï¼‰: {exc}") from exc

    def capture_images(self):
        images = {}
        if self.external_camera:
            ext_left, _ = self.external_camera.capture_frame()
            if ext_left is not None:
                images[f"{self.external_serial}_left"] = ext_left
        if self.wrist_camera:
            wrist_left, _ = self.wrist_camera.capture_frame()
            if wrist_left is not None:
                images[f"{self.wrist_serial}_left"] = wrist_left
        return images

    def close(self):
        if self.external_camera:
            try:
                self.external_camera.close()
            except Exception:
                pass
        if self.wrist_camera:
            try:
                self.wrist_camera.close()
            except Exception:
                pass


class RoboAgent:
    def __init__(self, args):
        
        self.args = args
        self.log_lock = threading.Lock()

        # åˆå§‹åŒ– log_file ä¸º Noneï¼Œé¿å…çº¿ç¨‹è®¿é—®æ—¶æŠ¥é”™
        self.log_file = None
        self.log_file_path = None
        self.img_dir = None
        self.current_episode_dir = None

        self.left_image = None
        self.right_image = None
        self.wrist_image = None

        self.image_lock = threading.Lock()
        self.image_thread = None
        self.image_thread_stop_event = threading.Event()
        self.manual_cam_mgr: Optional[ManualCameraManager] = None
        self.current_subtask_lock = threading.Lock()
        self.subtask_executed_done_lock = threading.Lock()
        self.post_run_lock = threading.Lock()

        self.current_subtask = None

        self.joint_position = None
        self.gripper_position = None
        self.running = True

        self.in_post_run = True  # è®¾ä¸ºTrueï¼Œé˜²æ­¢çº¿ç¨‹åœ¨ agent å‡†å¤‡å¥½å‰é”™è¯¯åœ°è¿è¡Œ
        self.episode_start = time.time()

        self.start_time = time.time()
        self.consecutive_failed_attempts = 0
        self.subtask_executed_done = False
        self.frame_buffer = []
        self.vlm_logs = []
        self.vlm_request_idx = 0
        self.episode_closed = False
        self.global_step = 0

        if self.args.use_env_camera:
            raise ValueError("Async mode only supports manual ZEDCamera capture; set use_env_camera=False.")

        # ç¦ç”¨ RobotEnv å†…ç½®ç›¸æœºåˆå§‹åŒ–ï¼Œæ”¹ä¸ºæ‰‹åŠ¨ ZED æŠ“å–ï¼ˆä¸ pi05_main_async ä¸€è‡´ï¼‰
        mcw.gather_zed_cameras = lambda: []
        self.log("Disabled env cameras; will use ZEDCamera manual capture.", "info")

        self.env = RobotEnv(action_space="joint_position", gripper_action_space="position")

        self.log("Created the droid env!", message_type="info")

        try:
            self.manual_cam_mgr = ManualCameraManager(self.args)
            self.log("ManualCameraManager initialized for ZED cameras.", "info")
        except Exception as e:
            self.log(f"Failed to initialize ManualCameraManager: {e}", "error")
            raise

        self.policy = websocket_client_policy.WebsocketClientPolicy(self.args.remote_host, self.args.remote_port)
        self.log(f"Successfully connected to {self.args.remote_host}:{self.args.remote_port}!", "info")

        self.init_vlm()
        self.log("Init RoboBrain done", "info")

        self.init_threads()
        self.log("Init threads done", "info")
    
    def init_vlm(self):
        from scripts.robobrain import RoboBrain
        self.vlm = RoboBrain(8000 if self.args.vllm_port is None else self.args.vllm_port)

    def init_threads(self):
        # åå°æŒç»­æŠ“å–ç›¸æœºå¸§ï¼Œé¿å…åœ¨å…¶ä»–çº¿ç¨‹è°ƒç”¨ get_observation å¼•å‘ç¯å¢ƒé”
        self.image_thread = threading.Thread(target=self.capture_images, daemon=True)
        self.image_thread.start()

        self.keyboard_listener_thread = threading.Thread(target=self.keyboard_listener, daemon=True)
        self.keyboard_listener_thread.start()
        
        self.check_subtask_success_thread = threading.Thread(target=self.check_subtask_success, daemon=True)
        self.check_subtask_success_thread.start()

        self.monitor_execution_time_thread = threading.Thread(target=self.monitor_execution_time, daemon=True)
        self.monitor_execution_time_thread.start()

    def capture_images(self):
        """
        èƒŒæ™¯çº¿ç¨‹ï¼šä»…æŠ“å–ç›¸æœºå›¾åƒå¹¶ç¼“å­˜ï¼Œé¿å…è·¨çº¿ç¨‹è°ƒç”¨ env.get_observation è§¦å‘ç¯å¢ƒé”ã€‚
        æœºå™¨äººçŠ¶æ€åœ¨ä¸»çº¿ç¨‹ä½¿ç”¨ env.get_state() åŒæ­¥è¯»å–ã€‚
        """
        target_interval = 1.0 / self.args.fetch_hz if self.args.fetch_hz > 0 else 0.0
        
        while self.running and not self.image_thread_stop_event.is_set():
            start = time.time()
            try:
                if self.manual_cam_mgr is None:
                    raise RuntimeError("ManualCameraManager is not initialized.")
                image_observations = self.manual_cam_mgr.capture_images()

                with self.image_lock:
                    for key in image_observations:
                        if self.args.left_camera_id in key and "left" in key:
                            self.left_image = image_observations[key]
                        elif self.args.right_camera_id in key and "left" in key:
                            self.right_image = image_observations[key]
                        elif self.args.wrist_camera_id in key and "left" in key:
                            self.wrist_image = image_observations[key]
            except KeyboardInterrupt:
                self.image_thread_stop_event.set()
                break
            except Exception as e:
                self.log(f"Error in capture_images: {e}", "error")
                time.sleep(0.05)
                continue

            elapsed = time.time() - start
            sleep_time = target_interval - elapsed
            if sleep_time > 0:
                time.sleep(sleep_time)

    def stop_image_thread(self):
        self.image_thread_stop_event.set()
        if self.image_thread and self.image_thread.is_alive():
            self.image_thread.join(timeout=1.0)
        if self.manual_cam_mgr:
            try:
                self.manual_cam_mgr.close()
            except Exception:
                pass

    def keyboard_listener(self):
        """Thread to listen for keyboard input"""
        while True:
            try:
                # å…ˆè¯»å–çŠ¶æ€ï¼Œé¿å…åœ¨é”å†… sleep
                with self.post_run_lock:
                    is_post_run = self.in_post_run
                
                if is_post_run == False:
                    # select æœ‰ 0.1s è¶…æ—¶ï¼Œè¿™é‡Œä¸éœ€è¦é¢å¤– sleep
                    if select.select([sys.stdin], [], [], 0.1)[0]:
                        sys.stdin.readline()
                        self.log("<Enter> detected, ending this episode.", message_type="info")
                        with self.post_run_lock:
                            self.in_post_run = True
                else:
                    time.sleep(0.1)  # åœ¨é”å¤– sleep
                    
            except Exception as e:
                self.log(f"Error in keyboard_listener: {e}", "error")

            if self.running == False:
                break
    
    def monitor_execution_time(self):
        """Thread to monitor task execution time"""
        while True:
            try:
                time.sleep(1.0) 
                with self.post_run_lock:
                    if self.in_post_run == False:
                        elapsed_time = time.time() - self.episode_start
                        if elapsed_time > self.args.max_duration:
                            self.log(f"Episode exceeded maximum duration of {self.args.max_duration}s", "warning")
                            self.in_post_run = True

            except Exception as e:
                self.log(f"Error in monitor_execution_time: {e}", "error")
            
            if self.running == False:
                break

    def check_subtask_success(self):
        """çº¿ç¨‹å‡½æ•°ï¼šå¼‚æ­¥æ£€æŸ¥å­ä»»åŠ¡æ˜¯å¦å®Œæˆ"""
        while True:
            current_subtask_local = None

            with self.post_run_lock:
                is_post_run = self.in_post_run

            try:
                if is_post_run == False:
                    
                    with self.current_subtask_lock:
                        current_subtask_local = self.current_subtask

                    if current_subtask_local is not None:
                        
                        with self.image_lock:
                            current_image_raw = self.left_image
                            current_image = process_image(current_image_raw, crop_ratios=CROP_RATIOS)
                        
                        if current_image is None:
                            self.log("check_subtask_success: å›¾åƒå°šæœªå‡†å¤‡å¥½, è·³è¿‡æ­¤æ¬¡æ£€æŸ¥.", "warning")
                            time.sleep(1)
                            continue

                        # è·å– log_fileï¼ˆå¯èƒ½ä¸º Noneï¼‰
                        log_file = self._get_log_file()
                        
                        # æ‰§è¡Œ VLM æ£€æŸ¥
                        self.log(f"[VLM] Starting subtask completion check for: '{current_subtask_local}'", "debug")
                        check_start = time.time()
                        vl_inputs = {
                            "images": {
                                "current_image": current_image
                            },
                            "user_prompt": current_subtask_local
                        }
                        prompt_text = self.vlm._build_prompt("subtask_complete_check", vl_inputs)
                        with time_scope("subtask complete check", log_file):
                            subtask_completed_str: str = self.vlm.request_task(
                                task_name="subtask_complete_check",
                                vl_inputs=vl_inputs
                            )
                        self._log_vlm_interaction(
                            "subtask_complete_check",
                            vl_inputs,
                            subtask_completed_str,
                            check_start,
                            time.time(),
                            prompt_text,
                        )
                        self._log_vlm_interaction(
                            "subtask_complete_check",
                            {"images": {"current_image": current_image}, "user_prompt": current_subtask_local},
                            subtask_completed_str,
                            check_start,
                            time.time(),
                        )
                        
                        check_duration = time.time() - check_start
                        self.log(f"[VLM] Subtask check completed in {check_duration:.4f}s, response: {subtask_completed_str[:100]}...", "debug")

                        with self.subtask_executed_done_lock:
                            self.subtask_executed_done = extract_boolean_answer(subtask_completed_str)
                            subtask_executed_done = self.subtask_executed_done
                        
                        if subtask_executed_done is None:
                            self.log("Error, subtask checking did not output in the expected format", "error")
                        elif subtask_executed_done:
                            self.log(f"âœ… Subtask '{current_subtask_local}' is COMPLETED.", message_type="outcome")
                        else:
                            self.log(f"â³ Subtask '{current_subtask_local}' is NOT completed, continue!", message_type="outcome")
            
            except Exception as e:
                self.log(f"Error in check_subtask_success: {e}", "error")

            time.sleep(3)

            if self.running == False:
                break

    def _get_log_file(self):
        """å®‰å…¨åœ°è·å– log_fileï¼Œå¦‚æœæœªåˆå§‹åŒ–åˆ™è¿”å› None"""
        if hasattr(self, 'log_file') and self.log_file and not self.log_file.closed:
            return self.log_file
        return None

    def get_global_instruction(self) -> list:
        """VLM ç”Ÿæˆå…¨å±€å­ä»»åŠ¡åˆ—è¡¨"""
        log_file = self._get_log_file()
        
        self.log("[VLM] Requesting global instruction proposal...", "info")
        proposal_start = time.time()
        vl_inputs = {
            "images": {
                "initial_image": self.initial_image,
            },
            "user_prompt": self.user_prompt
        }
        prompt_text = self.vlm._build_prompt("global_instruction_proposal", vl_inputs)
        
        with time_scope("global instruction proposal", log_file):
            global_task_str: str = self.vlm.request_task(
                task_name="global_instruction_proposal",
                vl_inputs=vl_inputs
            )
        self._log_vlm_interaction(
            "global_instruction_proposal",
            vl_inputs,
            global_task_str,
            proposal_start,
            time.time(),
            prompt_text,
        )
        
        proposal_duration = time.time() - proposal_start
        self.log(f"[VLM] Global instruction proposal completed in {proposal_duration:.4f}s", "info")
        self.log(f"[VLM] Raw response: {global_task_str}", message_type="debug")
        
        subtask_list: list = parse_llm_output_to_list_regex(global_task_str)
        self.log(f"[VLM] Parsed {len(subtask_list)} subtasks: {subtask_list}", message_type="outcome")
        return subtask_list

    def check_global_complete(self) -> bool:
        """VLM æ£€æŸ¥å…¨å±€ä»»åŠ¡æ˜¯å¦å®Œæˆ"""
        with self.image_lock:
            current_image = process_image(self.left_image, crop_ratios=CROP_RATIOS)

        log_file = self._get_log_file()
        
        self.log("[VLM] Checking global task completion...", "info")
        check_start = time.time()
        vl_inputs = {
            "images": {
                "initial_image": self.initial_image,
                "current_image": current_image
            },
            "user_prompt": self.user_prompt
        }
        prompt_text = self.vlm._build_prompt("global_task_complete_check", vl_inputs)
        
        with time_scope("global task complete check", log_file):
            task_completed_str: str = self.vlm.request_task(
                task_name="global_task_complete_check",
                vl_inputs=vl_inputs
            )
        self._log_vlm_interaction(
            "global_task_complete_check",
            vl_inputs,
            task_completed_str,
            check_start,
            time.time(),
            prompt_text,
        )
        
        check_duration = time.time() - check_start
        self.log(f"[VLM] Global check completed in {check_duration:.4f}s, response: {task_completed_str[:100]}...", "debug")
        
        task_completed = extract_boolean_answer(task_completed_str)

        if task_completed is None:
            self.log("Error, global checking did not output in the expected format.", "error")
            return False
            
        if task_completed:
            self.log(f"âœ… Global task '{self.user_prompt}' is COMPLETED!", message_type="outcome")
        else:
            self.log(f"â³ Global task '{self.user_prompt}' is NOT completed, continuing...", message_type="outcome")
            
        return task_completed

    ################################################ æ‰§è¡Œå‡½æ•° (Execution Functions) ###############################################
    
    def init_episode(self):
        """åˆå§‹åŒ–ä¸€ä¸ªæ–°çš„ episodeï¼šåˆ›å»ºæ—¥å¿—ç›®å½•å’Œæ—¥å¿—æ–‡ä»¶"""
        try:
            # ä½¿ç”¨åŒ—äº¬æ—¶é—´åˆ›å»ºæ—¶é—´æˆ³
            beijing_now = datetime.now(BEIJING_TZ)
            timestamp = beijing_now.strftime("%Y%m%d_%H%M%S")
            
            self.current_episode_dir = os.path.join(self.args.record_dir, timestamp)
            os.makedirs(self.current_episode_dir, exist_ok=True)

            # åˆ›å»ºæ—¥å¿—æ–‡ä»¶
            self.log_file_path = os.path.join(self.current_episode_dir, 'run.log')
            self.log_file = open(self.log_file_path, 'w', encoding='utf-8')
            
            # åˆ›å»º images æ–‡ä»¶å¤¹
            self.img_dir = os.path.join(self.current_episode_dir, 'images')
            os.makedirs(self.img_dir, exist_ok=True)
            # æ‰©å±•ç”¨äºå¸§å’Œ VLM å›¾åƒçš„ç›®å½•
            self.frames_dir = os.path.join(self.current_episode_dir, 'frames')
            os.makedirs(self.frames_dir, exist_ok=True)
            self.vlm_images_dir = os.path.join(self.current_episode_dir, 'vlm_images')
            os.makedirs(self.vlm_images_dir, exist_ok=True)

            # é‡ç½®ç¼“å†²
            self.frame_buffer = []
            self.vlm_logs = []
            self.vlm_request_idx = 0
            self.episode_closed = False
            self.global_step = 0

            # è®© VLM ä¹Ÿä½¿ç”¨åŒä¸€ä¸ªæ—¥å¿—ç³»ç»Ÿ
            self.vlm.set_logging(self.log_file, self.img_dir)

            # å†™å…¥ episode å¤´ä¿¡æ¯
            self.log("=" * 80, "info")
            self.log(f"Episode initialized at: {self.current_episode_dir}", "info")
            self.log(f"Beijing Time: {beijing_now.strftime('%Y-%m-%d %H:%M:%S.%f')}", "info")
            self.log(f"User prompt: {self.user_prompt}", "info")
            self.log("=" * 80, "info")
                
        except Exception as e:
            self.log(f"Error in init_episode: {e}", "error")
            self.running = False 

    def reset_flags(self):
        """é‡ç½® episode ç›¸å…³çš„æ ‡å¿—ä½"""
        self.log("Resetting episode flags.", "debug")
        with self.post_run_lock:
            self.in_post_run = False
        with self.subtask_executed_done_lock:
            self.subtask_executed_done = False
        self.episode_start = time.time()
        self.consecutive_failed_attempts = 0

    def run_agent(self):
        """ä¸»æ‰§è¡Œå‡½æ•°"""
        self.user_prompt = input("Please enter your instruction\n>>>  ")

        # ç­‰å¾…åå°æŠ“å–çº¿ç¨‹å‡†å¤‡å¥½é¦–å¸§
        self.log("Waiting for camera to be ready...", "info")
        wait_start = time.time()

        while True:
            with self.image_lock:
                ready_image = self.left_image
            if ready_image is not None:
                break
            if time.time() - wait_start > self.args.first_frame_timeout_s:
                self.log(f"Camera timeout after {self.args.first_frame_timeout_s}s!", "error")
                return
            time.sleep(0.1)
        
        self.log(f"Camera ready after {time.time() - wait_start:.2f}s", "info")
        
        with self.image_lock:
            self.initial_image = process_image(self.left_image, crop_ratios=CROP_RATIOS)

        if self.initial_image is None:
            self.log("Failed to get initial_image from camera. Exiting.", "error")
            return

        self.log(f"User prompt received: {self.user_prompt}", message_type="outcome")

        while True:  # Outer loop (for entire task)

            self.time_step = 0
            self.init_episode()

            # VLM ç”Ÿæˆå­ä»»åŠ¡åˆ—è¡¨
            subtask_list: list = self.get_global_instruction()
            self.log(f"Generated {len(subtask_list)} subtasks for execution", "info")

            subtask_index = 0

            while True:  # Inner loop (for sub-tasks)
                
                # Step1: ä» subtask_list è·å–å½“å‰éœ€è¦æ‰§è¡Œçš„å­ä»»åŠ¡
                with self.current_subtask_lock:
                    try:
                        self.current_subtask = subtask_list[subtask_index]
                        current_subtask = self.current_subtask
                    except IndexError:
                        self.log("All subtasks completed (list exhausted)", "info")
                        with self.post_run_lock:
                            self.in_post_run = True
                        break

                self.log("-" * 60, "info")
                self.log(f"[SUBTASK {subtask_index + 1}/{len(subtask_list)}] Starting: {current_subtask}", "info")
                self.log("-" * 60, "info")

                # Step2: Reset ä¸ä»»åŠ¡ç›¸å…³çš„æ ‡å¿—ä½
                self.reset_flags()

                # æ¸…ç©ºç»ˆç«¯ç¼“å†²åŒº
                clear_input_buffer()

                # Step3ï¼šæ‰§è¡Œ
                execute_start = time.time()
                self.execute(current_subtask)
                execute_duration = time.time() - execute_start
                self.log(f"[SUBTASK {subtask_index + 1}] Execution took {execute_duration:.2f}s", "info")
                
                # Step4: æ£€æŸ¥å…¨å±€æŒ‡ä»¤æ˜¯å¦å®Œæˆ
                global_task_completed: bool = self.check_global_complete()

                if global_task_completed:
                    self.log("ğŸ‰ Global task completed!", "outcome")
                    break

                subtask_index += 1
            
            self.close_episode()
            self.log("Task finished, exiting run_agent.", "info")
            break
    
    def execute(self, subtask: str):
        """
        æ§åˆ¶æœºæ¢°è‡‚æ‰§è¡Œå­ä»»åŠ¡
        é€€å‡ºæ¡ä»¶ï¼š
            1. in_post_run = True (é”®ç›˜ä¸­æ–­æˆ–å¼‚å¸¸)
            2. subtask_executed_done = True (VLM åˆ¤æ–­å­ä»»åŠ¡å®Œæˆ)
            3. è¶…è¿‡ max_subtask_timesteps
        """
        actions_from_chunk_completed = 0
        pred_action_chunk = None
        
        timestep = 0 
        self.log(f"[EXECUTE] Starting execution of: {subtask}", "info")

        with self.subtask_executed_done_lock:
            subtask_executed_done = self.subtask_executed_done

        with self.post_run_lock:
            in_post_run = self.in_post_run

        chunk_count = 0
        current_left_image = None
        current_wrist_image = None
        
        while subtask_executed_done == False and in_post_run == False:
            
            if timestep >= self.args.max_subtask_timesteps:
                self.log(f"[EXECUTE] âš ï¸ Reached max_timesteps ({self.args.max_subtask_timesteps}), stopping.", "warning")
                with self.post_run_lock:
                    self.in_post_run = True
                break

            start_time = time.time()
            try:
                if actions_from_chunk_completed == 0 or actions_from_chunk_completed >= self.args.open_loop_horizon:
                    actions_from_chunk_completed = 0
                    chunk_count += 1

                    with self.image_lock:
                        raw_left_image = self.left_image
                        raw_wrist_image = self.wrist_image

                    if raw_left_image is None or raw_wrist_image is None:
                        self.log("[EXECUTE] Images not ready yet, waiting...", "warning")
                        time.sleep(0.05)
                        continue

                    try:
                        # çŠ¶æ€åœ¨ä¸»çº¿ç¨‹åŒæ­¥è¯»å–ï¼Œé¿å…è·¨çº¿ç¨‹è§¦å‘ç¯å¢ƒé”
                        state_dict, _ = self.env.get_state()
                        raw_obs = {
                            "robot_state": state_dict,
                            "image": {
                                f"{self.args.left_camera_id}_left": raw_left_image,
                                f"{self.args.wrist_camera_id}_left": raw_wrist_image,
                            },
                        }
                        curr_obs = _extract_observation(self.args, raw_obs, crop_ratios=CROP_RATIOS)

                        current_left_image = curr_obs["left_image"]
                        current_wrist_image = curr_obs["wrist_image"]
                        current_joint_pos = curr_obs["joint_position"]
                        current_gripper_pos = curr_obs["gripper_position"]

                        self.joint_position = current_joint_pos
                        self.gripper_position = current_gripper_pos
                    except Exception as e:
                        self.log(f"[EXECUTE] build observation failed: {e}", "error")
                        time.sleep(0.05)
                        continue

                    request_data = {
                        "observation/image": image_tools.resize_with_pad(current_left_image, 224, 224),
                        "observation/wrist_image": image_tools.resize_with_pad(current_wrist_image, 224, 224),
                        "observation/state": np.concatenate((current_joint_pos, current_gripper_pos), axis=0),
                        "prompt": subtask,
                    }

                    with prevent_keyboard_interrupt():
                        inference_start = time.time()
                        pred_action_chunk = self.policy.infer(request_data)["actions"]
                        pred_action_chunk = pred_action_chunk[:, :8]
                        inference_time = time.time() - inference_start
                        
                        # æ¯ä¸ª chunk å¼€å§‹æ—¶è®°å½•
                        self.log(f"[VLA] Chunk {chunk_count}: inference={inference_time:.4f}s, timestep={timestep}", "debug")

                action = pred_action_chunk[actions_from_chunk_completed]
                actions_from_chunk_completed += 1

                # Gripper action thresholding
                if action[-1].item() > 0.20:
                    action = np.concatenate([action[:-1], np.ones((1,))])
                else:
                    action = np.concatenate([action[:-1], np.zeros((1,))])

                self.env.step(action)
                # ç¼“å­˜å½“å‰å¸§ï¼Œç»“æŸåç»Ÿä¸€å†™ç›˜ï¼ˆæ¯æ­¥éƒ½å­˜ï¼‰
                try:
                    if current_left_image is not None or current_wrist_image is not None:
                        self.frame_buffer.append(
                            {
                                "subtask": subtask,
                                "step": timestep,
                                "global_step": self.global_step,
                                "left_image": current_left_image.copy() if current_left_image is not None else None,
                                "wrist_image": current_wrist_image.copy() if current_wrist_image is not None else None,
                            }
                        )
                except Exception:
                    pass

                timestep += 1
                self.global_step += 1 

                # æ¯ 50 æ­¥è®°å½•ä¸€æ¬¡è¿›åº¦
                if timestep % 50 == 0:
                    self.log(f"[EXECUTE] Progress: timestep={timestep}, chunks={chunk_count}", "info")

                elapsed_time = time.time() - start_time
                sleep_time = (1 / self.args.control_frequency) - elapsed_time
                if sleep_time > 0:
                    time.sleep(sleep_time)

                # æ›´æ–°å¾ªç¯æ¡ä»¶å˜é‡
                with self.subtask_executed_done_lock:
                    subtask_executed_done = self.subtask_executed_done
                with self.post_run_lock:
                    in_post_run = self.in_post_run

            except KeyboardInterrupt:
                self.log("[EXECUTE] â›” KeyboardInterrupt detected, stopping.", "info")
                with self.post_run_lock:
                    self.in_post_run = True
                break
            except Exception as e:
                self.log(f"[EXECUTE] âŒ FATAL Error: {e}", "error")
                with self.post_run_lock:
                    self.in_post_run = True
                break

        # è®°å½•å­ä»»åŠ¡ç»“æŸçŠ¶æ€
        status = "âœ… DONE" if subtask_executed_done else ("â›” INTERRUPTED" if in_post_run else "â“ UNKNOWN")
        self.log(f"[EXECUTE] Finished after {timestep} timesteps ({chunk_count} chunks). Status: {status}", "info")

    def log(self, message: str, message_type: str = "info"):
        """
        çº¿ç¨‹å®‰å…¨çš„æ—¥å¿—å‡½æ•°ï¼ŒåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶
        ä½¿ç”¨åŒ—äº¬æ—¶é—´ï¼ˆUTC+8ï¼‰ï¼Œç²¾ç¡®åˆ°å¾®ç§’
        """
        with self.log_lock:
            # è·å–åŒ—äº¬æ—¶é—´ï¼Œç²¾ç¡®åˆ°å¾®ç§’
            timestamp = get_beijing_timestamp()
            log_message = f"[{timestamp}] [{message_type.upper():8}] {message}"
            mt_lower = message_type.lower()

            # ANSI é¢œè‰²
            color_map = {
                "debug": "\033[90m",
                "info": "\033[0m",
                "outcome": "\033[92m",
                "warning": "\033[93m",
                "error": "\033[91m",
                "subtask": "\033[95m",  # ç´«è‰²
            }

            color_prefix = color_map.get(mt_lower, "\033[0m")

            # ç‰¹æ®Šåˆ¤å®šï¼šepisode headerã€subtask å¯åŠ¨ç­‰ç”¨ç´«è‰²
            if mt_lower == "info":
                if (
                    "Episode initialized at" in message
                    or "Beijing Time" in message
                    or "User prompt" in message
                    or message.strip().startswith("=")
                    or "Generated " in message
                    or "[SUBTASK" in message
                    or "Starting execution of" in message
                ):
                    color_prefix = color_map["subtask"]

            # outcomeï¼šæœªå®Œæˆç”¨é»„ï¼Œå®Œæˆç”¨ç»¿
            if mt_lower == "outcome":
                if "NOT completed" in message or "â³" in message:
                    color_prefix = color_map["warning"]
                if "COMPLETED" in message or "âœ…" in message:
                    color_prefix = color_map["outcome"]

            color_reset = "\033[0m"

            # å§‹ç»ˆè¾“å‡ºåˆ°æ§åˆ¶å°ï¼ˆå¸¦é¢œè‰²ï¼‰
            print(f"{color_prefix}{log_message}{color_reset}")
            
            # å¦‚æœæ—¥å¿—æ–‡ä»¶å·²æ‰“å¼€ï¼ŒåŒæ—¶å†™å…¥æ–‡ä»¶
            if self.log_file is not None and not self.log_file.closed:
                try:
                    self.log_file.write(log_message + "\n")
                    self.log_file.flush()
                except Exception as e:
                    print(f"[{get_beijing_timestamp_short()}] [LOG_ERROR] Failed to write to log file: {e}")

    def save_image(self, image, filename_prefix: str):
        """ä¿å­˜å›¾åƒåˆ°å½“å‰ episode çš„ images ç›®å½•"""
        if image is None:
            self.log(f"Cannot save image {filename_prefix}, image is None.", "warning")
            return
            
        if self.img_dir is None:
            self.log("Cannot save image, img_dir is not set (episode not initialized?).", "error")
            return
             
        try:
            # ä½¿ç”¨åŒ—äº¬æ—¶é—´ä½œä¸ºæ–‡ä»¶åçš„ä¸€éƒ¨åˆ†
            beijing_ts = datetime.now(BEIJING_TZ).strftime("%H%M%S_%f")
            img_path = os.path.join(self.img_dir, f"{filename_prefix}_{beijing_ts}.png")
            Image.fromarray(image).save(img_path)
            self.log(f"Image saved to {img_path}", "debug")
        except Exception as e:
            self.log(f"Failed to save image {filename_prefix}: {e}", "error")

    def _log_vlm_interaction(self, task_name: str, vl_inputs: dict, response: str, start_ts: float, end_ts: float, prompt_text: str | None = None):
        """è®°å½• VLM è¯·æ±‚/å“åº”ï¼Œå›¾åƒæš‚å­˜åˆ°å†…å­˜ï¼Œç»“æŸæ—¶ç»Ÿä¸€è½ç›˜ã€‚"""
        self.vlm_request_idx += 1
        request_id = self.vlm_request_idx
        entry = {
            "request_id": request_id,
            "task_name": task_name,
            "start_time": start_ts,
            "end_time": end_ts,
            "duration_s": end_ts - start_ts,
            "inputs": {k: v for k, v in vl_inputs.items() if k != "images"} if isinstance(vl_inputs, dict) else {},
            "prompt": prompt_text,
            "images": [],
            "images_pending": [],
            "response": response,
        }
        images = vl_inputs.get("images", {}) if isinstance(vl_inputs, dict) else {}
        for key, img in images.items():
            if img is None:
                continue
            try:
                entry["images_pending"].append({"key": key, "image": img.copy()})
            except Exception:
                pass
        self.vlm_logs.append(entry)

    def close_episode(self):
        """æ¸…ç† episode èµ„æº"""
        if getattr(self, "episode_closed", False):
            return

        self.log("=" * 80, "info")
        self.log("Closing episode.", "info")
        self.log(f"End time (Beijing): {get_beijing_timestamp()}", "info")
        self.log("=" * 80, "info")

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå†™ç›˜ï¼Œæ— æŸ PNGï¼ˆä½å‹ç¼©åŠ é€Ÿï¼‰
        save_tasks = []
        max_workers = max(8, (os.cpu_count() or 8))

        def _save_png(img_arr, path):
            Image.fromarray(img_arr).save(path, compress_level=1)

        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as pool:
            # è½ç›˜ç¼“å­˜çš„å¸§
            if getattr(self, "frame_buffer", None) and getattr(self, "frames_dir", None):
                for item in self.frame_buffer:
                    subtask_safe = re.sub(r"[^a-zA-Z0-9_-]+", "_", item.get("subtask", "subtask"))
                    step_idx = item.get("step", 0)
                    g_step = item.get("global_step", step_idx)
                    for key in ["left_image", "wrist_image"]:
                        img = item.get(key)
                        if img is None:
                            continue
                        img_path = os.path.join(self.frames_dir, f"{key}_step_{g_step}_{subtask_safe}.png")
                        save_tasks.append(pool.submit(_save_png, img, img_path))

            # è½ç›˜ VLM è¯·æ±‚é‡Œçš„å›¾åƒ
            if getattr(self, "vlm_logs", None) and getattr(self, "vlm_images_dir", None):
                for entry in self.vlm_logs:
                    if entry.get("images"):
                        continue
                    paths = []
                    pending_images = entry.pop("images_pending", [])
                    for img_item in pending_images:
                        key = img_item.get("key", "image")
                        img = img_item.get("image")
                        if img is None:
                            continue
                        img_path = os.path.join(self.vlm_images_dir, f"vlm_request_image_{entry['request_id']}_{key}.png")
                        paths.append({"key": key, "path": img_path})
                        save_tasks.append(pool.submit(_save_png, img, img_path))
                    entry["images"] = paths

            for task in save_tasks:
                try:
                    task.result()
                except Exception as e:
                    self.log(f"Image save task failed: {e}", "warning")

        # å†™ VLM è¯·æ±‚æ—¥å¿—
        if getattr(self, "vlm_logs", None):
            try:
                log_path = os.path.join(self.current_episode_dir or ".", "vlm_requests.jsonl")
                with open(log_path, "w", encoding="utf-8") as f:
                    for entry in self.vlm_logs:
                        f.write(json.dumps(entry, ensure_ascii=False) + "\n")
                self.log(f"VLM requests saved to {log_path}", "info")
                # å¯è¯»æ€§æ›´å¥½çš„ç‰ˆæœ¬ï¼ˆç¼©è¿›ï¼‰ï¼Œä¾¿äºäººå·¥æŸ¥çœ‹
                pretty_path = os.path.join(self.current_episode_dir or ".", "vlm_requests_readable.json")
                with open(pretty_path, "w", encoding="utf-8") as f:
                    json.dump(self.vlm_logs, f, ensure_ascii=False, indent=2)
                self.log(f"VLM requests (readable) saved to {pretty_path}", "info")
            except Exception as e:
                self.log(f"Failed to save VLM logs: {e}", "warning")

        # å…³é—­æ—¥å¿—æ–‡ä»¶
        if self.log_file is not None and not self.log_file.closed:
            try:
                self.log_file.flush()
                self.log_file.close()
                print(f"[{get_beijing_timestamp_short()}] [INFO    ] Log file closed: {self.log_file_path}")
            except Exception as e:
                print(f"[{get_beijing_timestamp_short()}] [ERROR   ] Failed to close log file: {e}")
            finally:
                self.log_file = None

        self.episode_closed = True


if __name__ == '__main__':
    # 1. Parse arguments
    args = tyro.cli(Args)
    
    # 2. Create the agent
    agent = RoboAgent(args)
    
    # 3. Run the agent
    try:
        agent.run_agent()
    except KeyboardInterrupt:
        agent.log("Shutdown requested by user.", "info")
    except Exception as e:
        agent.log(f"An uncaught exception occurred: {e}", "error")
    finally:
        agent.running = False
        agent.stop_image_thread()
        agent.close_episode()
        agent.log("RoboAgent shutdown complete.", "info")
        sys.exit(0)
